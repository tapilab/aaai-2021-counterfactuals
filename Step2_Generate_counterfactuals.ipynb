{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically generate counterfactual sentences by substituting causal terms with antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, time\n",
    "from itertools import combinations, cycle, product\n",
    "from IPython.display import display\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, random, re\n",
    "from collections import Counter\n",
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'my_data_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counterfactual:\n",
    "    def __init__(self, df_train, df_test, moniker):\n",
    "        display(df_train.head(1))\n",
    "        self.moniker = moniker\n",
    "        self.train = df_train\n",
    "        self.test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_imdb(data_file):\n",
    "    \"\"\"\n",
    "    Pre-process to get original text and counterfactual text\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_file, sep='\\t')\n",
    "\n",
    "    \n",
    "    combined_text = df.Text.values\n",
    "    combined_batch_id = df.batch_id.values\n",
    "    \n",
    "    org_idx = [i for i in range(df.shape[0]) if(i % 2 == 0)]\n",
    "    ct_idx = [i for i in range(df.shape[0]) if(i % 2 != 0)]\n",
    "    \n",
    "    org_batch_id = combined_batch_id[org_idx]\n",
    "    ct_batch_id = combined_batch_id[ct_idx]\n",
    "    if np.any(org_batch_id != ct_batch_id):\n",
    "        print('Error: batch id not match!')\n",
    "        return\n",
    "    \n",
    "    data = {}\n",
    "    data['batch_id'] = org_batch_id\n",
    "    data['text'] = combined_text[org_idx]\n",
    "    data['ct_text_amt'] = combined_text[ct_idx]\n",
    "    data['label'] = df.Sentiment.values[org_idx]\n",
    "    data['ct_label'] = df.Sentiment.values[ct_idx]\n",
    "    df_data = pd.DataFrame(data)\n",
    "    \n",
    "    map_lb = {'Positive':1, 'Negative':-1}\n",
    "    df_data.replace({'label':map_lb, 'ct_label':map_lb}, inplace=True)\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sents(df):\n",
    "    \"\"\"\n",
    "    - Select test sentences that contain one of the causal terms from full vocab\n",
    "    \"\"\"\n",
    "    df_antonym_vocab = pd.read_csv(data_path+'kindle_ct/kindle_vocab_antonym_causal.csv')\n",
    "    keywords = list(df_antonym_vocab[df_antonym_vocab.causal == 1].term.values)\n",
    "    \n",
    "    vec = CountVectorizer(min_df=5, binary=True, max_df=.8)\n",
    "    X = vec.fit_transform(df.text.values)\n",
    "    y = df.label.values\n",
    "    \n",
    "    wd_sents = {}\n",
    "    sent_idx = set()\n",
    "    for wd in keywords:\n",
    "        try:\n",
    "            s_idx = np.nonzero(X[:,vec.vocabulary_[wd]])[0]\n",
    "            wd_sents[wd] = s_idx\n",
    "            sent_idx.update(s_idx)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return df.iloc[list(sent_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was a very fun story</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not fast moving but a very well managed pace</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The story line is an interesting take on zombie mythology and is a great journey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series is always a good read</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Did not like it very much</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                text  \\\n",
       "0   This was a very fun story                                                          \n",
       "1   Not fast moving but a very well managed pace                                       \n",
       "2   The story line is an interesting take on zombie mythology and is a great journey   \n",
       "4   series is always a good read                                                       \n",
       "10  Did not like it very much                                                          \n",
       "\n",
       "    rating  label  flag  \n",
       "0   5       1      test  \n",
       "1   5       1      test  \n",
       "2   5       1      test  \n",
       "4   5       1      test  \n",
       "10  1      -1      test  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kindle = pickle.load(open(data_path+\"kindle_ct/causal_sents/kindle_data.pkl\",'rb'))\n",
    "df_test = df_kindle[df_kindle['flag']=='test']\n",
    "\n",
    "df_test_select = select_sents(df_test)\n",
    "display(df_test_select.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(moniker):\n",
    "    \"\"\"\n",
    "    - get kindle or imdb from different files\n",
    "    \"\"\"\n",
    "    if(moniker == 'kindle'):\n",
    "        df_kindle = pickle.load(open(data_path+\"kindle_ct/causal_sents/kindle_data.pkl\",'rb'))\n",
    "        df_train = df_kindle[df_kindle['flag']=='selected_train']\n",
    "        df_test = df_kindle[df_kindle['flag']=='test']\n",
    "        df_antonym_vocab = pd.read_csv(data_path+'kindle_ct/kindle_vocab_antonym_causal.csv')\n",
    "        df_identified_causal = pd.read_csv(data_path+'kindle_ct/ITE/kindle_identified_causal.csv')\n",
    "    elif(moniker == 'imdb'):\n",
    "        df_train = pre_process_imdb(data_file = data_path + \"imdb_ct/train_paired.tsv\")\n",
    "        df_test = pre_process_imdb(data_file = data_path + \"imdb_ct/test_paired.tsv\")\n",
    "        df_antonym_vocab = pd.read_csv(data_path+'imdb_ct/imdb_vocab_antonym_causal.csv')\n",
    "        df_identified_causal = pd.read_csv(data_path+'imdb_ct/imdb_identified_causal.csv')\n",
    "    elif(moniker == 'imdb_sents'):\n",
    "        df_train = pickle.load(open(data_path+\"imdb_ct/train_paired_sents.pkl\", 'rb'))\n",
    "        df_test = pickle.load(open(data_path+\"imdb_ct/test_paired_sents.pkl\", 'rb'))\n",
    "        df_antonym_vocab = pd.read_csv(data_path+'imdb_ct/imdb_vocab_antonym_causal.csv')\n",
    "        df_identified_causal = pd.read_csv(data_path+'imdb_ct/imdb_identified_causal.csv')\n",
    "        \n",
    "    return df_train, df_test, df_antonym_vocab, df_identified_causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_antonyms(vocab, causal_words):\n",
    "    \"\"\"\n",
    "    - antonyms: top term with opposite coefficient;\n",
    "    - get antonyms for all words in the vocab\n",
    "    - Help provide more options for manually edit counterfactual examples\n",
    "    - # 90 min for imdb vocab\n",
    "    \"\"\"\n",
    "    term_antonyms = {}\n",
    "    for ti, term in enumerate(causal_words):\n",
    "        try:\n",
    "            term_coef = vocab[term]\n",
    "\n",
    "            ant_terms = {} # antonym and its coef\n",
    "            for ant in dictionary.antonym(term):\n",
    "                if (ant in vocab) and (term_coef * vocab[ant] < 0): # opposite coef, \n",
    "                    ant_terms[ant] = vocab[ant]\n",
    "\n",
    "            if(len(ant_terms) == 0):\n",
    "                for syn in dictionary.synonym(term):\n",
    "                    if(len(re.findall('\\w+', syn)) == 1):\n",
    "                        for ant in dictionary.antonym(syn):\n",
    "                            if (ant in vocab) and (ant != term) and (term_coef * vocab[ant] < 0): # \n",
    "                                ant_terms[ant] = vocab[ant]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        term_antonyms[term] = ant_terms\n",
    "        \n",
    "    return term_antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classifier(train_text, train_label, test_text, test_label, report=True, train='comb'):\n",
    "    \"\"\"\n",
    "    Fit a basic binary classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    vec = CountVectorizer(min_df=5, binary=True, max_df=.8)\n",
    "    if(train == 'comb'):\n",
    "        X = vec.fit_transform(list(train_text) + list(test_text))\n",
    "        X_train = vec.transform(train_text)\n",
    "        X_test = vec.transform(test_text)\n",
    "    elif(train == 'train'):\n",
    "        X_train = vec.fit_transform(list(train_text))\n",
    "        X_test = vec.transform(test_text)\n",
    "        \n",
    "    clf = LogisticRegression(class_weight='auto', solver='lbfgs', max_iter=1000)\n",
    "    clf.fit(X_train, train_label)\n",
    "    \n",
    "    if(report):\n",
    "        print(classification_report(test_label, clf.predict(X_test)))\n",
    "        return clf, vec\n",
    "    else:\n",
    "        result = classification_report(test_label, clf.predict(X_test), output_dict=True)\n",
    "        return float('%.3f' % result['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_terms(clf, vec, topn=0, min_coef=0.5, show_data=False):\n",
    "    \"\"\"\n",
    "    - fit classifier\n",
    "    - Select features by: topn or min_coef\n",
    "    \"\"\"\n",
    "    df_vocab = pd.DataFrame({'term':vec.get_feature_names(),'coef':[float(\"%.3f\" % c) for c in clf.coef_[0]]})\n",
    "    \n",
    "    if(topn == 0 and min_coef == 0):\n",
    "        return df_vocab\n",
    "    \n",
    "    if(min_coef>0 and topn==0):\n",
    "        df_top_terms = df_vocab[(df_vocab['coef']>= min_coef) | (df_vocab['coef'] < 0-min_coef)]\n",
    "    elif(topn>0 and min_coef==0):\n",
    "        df_vocab['coef_abs'] = df_vocab['coef'].apply(lambda x: abs(x))\n",
    "        df_top_terms = df_vocab.sort_values(by=['coef_abs'], ascending=False).head(topn)\n",
    "        df_top_terms.drop(columns=['coef_abs'],inplace=True)\n",
    "    \n",
    "    if(show_data):\n",
    "        df_pos_terms = df_top_terms[df_top_terms['coef']>0]\n",
    "        df_neg_terms = df_top_terms[df_top_terms['coef']<0]\n",
    "        print(\"Features correlated with pos class: \\n\", [item['term']+'/'+str(item['coef']) for i, item in df_pos_terms.sort_values(by=['coef'], ascending=False).iterrows()])\n",
    "        print(\"\\nFeatures correlated with neg class: \\n\", [item['term']+'/'+str(item['coef']) for i, item in df_neg_terms.sort_values(by=['coef'], ascending=True).iterrows()])\n",
    "    \n",
    "    return df_top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_causal_words(df, df_causal_terms, flag='causal', show_data=True):\n",
    "    \"\"\"\n",
    "    Identify causal words in each sentence\n",
    "    - Use CSR matrix from CountVectorizer instead of regular expression\n",
    "    - flag = 'causal' or flag = 'bad' or flag='top'\n",
    "    \"\"\"\n",
    "    df[flag+'_wds'] = df['text'].apply(lambda x: [wd for wd in re.findall('\\w+', x.lower()) if wd in df_causal_terms.term.values])\n",
    "    df['n_'+flag+'_wds'] = df[flag+'_wds'].apply(lambda x: len(x))\n",
    "    \n",
    "    if(show_data):\n",
    "        print(\"%d out of %d sentences include %d %s words\" % (df[df['n_'+flag+'_wds']>0].shape[0], df.shape[0], df_causal_terms.shape[0], flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ct_sentences(df, df_causal_terms, flag='causal'):\n",
    "    \"\"\"\n",
    "    Generate counterfactual sentences for those contain causal words:\n",
    "        - substitute all the causal words to antonyms;\n",
    "        - antonyms: top term with opposite coefficient;\n",
    "        - If no antonyms, keep the original causal word;\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    \n",
    "    all_ct_wds = []\n",
    "    for ri, row in df.iterrows():\n",
    "        if row['n_'+flag+'_wds'] > 0:\n",
    "            words = re.findall('\\w+', row.text.lower())\n",
    "            new_wds = []\n",
    "            ct_wds = []\n",
    "            for wd in words:\n",
    "                if(wd in df_causal_terms.term.values):\n",
    "                    # randomly select antonym that has equal coef with current word\n",
    "                    sub_w = list(df_causal_terms[df_causal_terms['term'] == wd].antonyms.values[0].keys())\n",
    "\n",
    "                    if(len(sub_w) == 1):\n",
    "                        ct_wd = str(sub_w[0])\n",
    "                    elif(len(sub_w) > 1):\n",
    "                        ct_wd = str(random.sample(sub_w,1)[0])\n",
    "                    else: # if no antonyms then remove current word\n",
    "                        ct_wd = wd\n",
    "                        \n",
    "                    new_wds.append(ct_wd)\n",
    "                    ct_wds.append(ct_wd)\n",
    "                else:\n",
    "                    new_wds.append(wd)\n",
    "                \n",
    "            if(new_wds == words): # no antonym for the causal word\n",
    "                all_ct_wds.append([])\n",
    "                df.loc[ri, 'ct_text_'+flag] = ' '\n",
    "            else:    \n",
    "                all_ct_wds.append(ct_wds)\n",
    "                df.loc[ri, 'ct_text_'+flag] = ' '.join(new_wds)\n",
    "        else:\n",
    "            all_ct_wds.append([])\n",
    "            df.loc[ri, 'ct_text_'+flag] = ' '\n",
    "        \n",
    "        \n",
    "    df['ct_'+flag+'_wds'] = all_ct_wds       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(moniker,coef_thresh):\n",
    "    \"\"\"\n",
    "    1. Get train and test data from file and construct Counterfactual object\n",
    "    2. Get top words\n",
    "    3. Annotate/predict causal words\n",
    "    4. Generate antonyms for causal words\n",
    "    5. Automatically generate counterfactual samples for both training and testing data\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    \n",
    "    print(\"Experiments for %s\" % moniker)\n",
    "\n",
    "    # 1. Get train and test data from file and construct Counterfactual object\n",
    "    if(moniker == 'imdb_sents'):\n",
    "        df_train_comb, df_test_comb, df_antonym_vocab, df_identified_causal = get_data(moniker)\n",
    "        df_train = df_train_comb[df_train_comb['flag']=='original'][['batch_id','text','label']]\n",
    "        df_test = df_test_comb[df_test_comb['flag']=='original'][['batch_id','text','label']]\n",
    "        ds = Counterfactual(df_train, df_test, moniker)\n",
    "\n",
    "        ds.train_ct = df_train_comb[df_train_comb['flag']=='counterfactual'][['batch_id','text','label']]\n",
    "        ds.test_ct = df_test_comb[df_test_comb['flag']=='counterfactual'][['batch_id','text','label']]\n",
    "    else:\n",
    "        df_train, df_test, df_antonym_vocab, df_identified_causal = get_data(moniker)\n",
    "        ds = Counterfactual(df_train, df_test, moniker)\n",
    "        \n",
    "        if(moniker == 'kindle'):\n",
    "            ds.select_test = select_sents(df_test)\n",
    "    \n",
    "    ds.identified_causal_terms = df_identified_causal[df_identified_causal.identified_causal == 1]\n",
    "        \n",
    "    print('Train: %s' % str(Counter(df_train.label).items()))\n",
    "    print('Test: %s' % str(Counter(df_test.label).items()))\n",
    "\n",
    "    # 2. Get true causal terms from pre-annotated file\n",
    "    clf, vec = fit_classifier(train_text = df_train.text.values, train_label = df_train.label.values,\n",
    "                              test_text = df_test.text.values, test_label=df_test.label.values, \n",
    "                              report=True, train='train')\n",
    "    \n",
    "    vocab = get_top_terms(clf, vec, topn=0, min_coef=0, show_data=False)\n",
    "    \n",
    "    ds.antonym_vocab = df_antonym_vocab\n",
    "    ds.all_causal_terms = ds.antonym_vocab[(ds.antonym_vocab.causal == 1) & (ds.antonym_vocab.term.isin(vocab.term.values))]\n",
    "    ds.all_causal_terms['antonyms'] = ds.all_causal_terms['antonyms'].apply(lambda x: eval(x))\n",
    "    \n",
    "    # 3. Get top words\n",
    "    clf, vec = fit_classifier(train_text = df_train.text.values, train_label = df_train.label.values,\n",
    "                                   test_text = df_test.text.values, test_label=df_test.label.values, \n",
    "                              report=True, train='train')\n",
    "\n",
    "    ds.top_terms = get_top_terms(clf, vec, topn=0, min_coef=coef_thresh, show_data=True)\n",
    "\n",
    "    # Number of top terms not covered in the full vocab\n",
    "    missing_terms = [term for term in ds.top_terms.term if term not in ds.antonym_vocab.term.values]\n",
    "    print('\\n%d top terms: %d pos, %d neg, %d missing from full vocab\\n' % (ds.top_terms.shape[0], \n",
    "                                                ds.top_terms[ds.top_terms.coef>0].shape[0],\n",
    "                                                ds.top_terms[ds.top_terms.coef<0].shape[0],\n",
    "                                                                            len(missing_terms)))\n",
    "    print('Missing terms:', missing_terms)\n",
    "\n",
    "    # 3. Assign causal label to top words (load from pre-annotated file)\n",
    "    ds.top_terms['causal'] = [ds.antonym_vocab[ds.antonym_vocab['term'] == item.term].causal.values[0] if item.term in ds.antonym_vocab.term.values else 0 for i, item in ds.top_terms.iterrows()]\n",
    "    \n",
    "    # 4. Get antonyms for causal words    \n",
    "    ds.top_terms['antonyms'] = [eval(ds.antonym_vocab[ds.antonym_vocab['term'] == item.term].antonyms.values[0]) if item.term in ds.antonym_vocab.term.values else {} for i, item in ds.top_terms.iterrows()]\n",
    "    ds.top_terms['n_antonyms'] = ds.top_terms['antonyms'].apply(lambda x: len(x))\n",
    "    df_causal_terms = ds.top_terms[ds.top_terms['causal'] == 1]\n",
    "    df_bad_terms = ds.top_terms[ds.top_terms['causal'] == 0]\n",
    "    ds.identified_causal_terms['antonyms'] = [eval(ds.antonym_vocab[ds.antonym_vocab['term'] == item.term].antonyms.values[0]) if item.term in ds.antonym_vocab.term.values else {} for i, item in ds.identified_causal_terms.iterrows()]\n",
    "\n",
    "    print('\\nGet antonyms for %d out of %d causal terms' % (df_causal_terms[df_causal_terms['n_antonyms'] > 0].shape[0], ds.top_terms[ds.top_terms['causal'] == 1].shape[0]))\n",
    "    print('Closest opposite match identified causal terms: %d out of %d\\n' % (ds.identified_causal_terms[ds.identified_causal_terms.causal==1].shape[0],ds.identified_causal_terms.shape[0]))\n",
    "\n",
    "    # 5. Automatically generate counterfactual samples for both training and testing data\n",
    "    for flag, df_ct_terms in zip(['causal','bad','top','identified_causal','all_causal'],[df_causal_terms, df_bad_terms, ds.top_terms, ds.identified_causal_terms, ds.all_causal_terms]):\n",
    "        identify_causal_words(ds.train, df_ct_terms, flag, show_data=True)\n",
    "        generate_ct_sentences(ds.train, df_ct_terms, flag)\n",
    "\n",
    "        identify_causal_words(ds.test, df_ct_terms, flag, show_data=True)\n",
    "        generate_ct_sentences(ds.test, df_ct_terms,flag)\n",
    "    \n",
    "    \n",
    "    if(moniker == 'kindle'):\n",
    "        df_annotate_ct = pd.read_csv(data_path+'kindle_ct/kindle_ct_edit_500.csv')\n",
    "        ds.test['ct_text_amt'] = [df_annotate_ct[df_annotate_ct['id']==idx]['ct_text_amt'].values[0] for idx in ds.test.index.values]\n",
    "        ds.select_test['ct_text_amt'] = ds.test.loc[list(ds.select_test.index.values)]['ct_text_amt'].values\n",
    "        ds.select_test['ct_label'] = ds.select_test['label'].apply(lambda x: 0-x)\n",
    "    if(moniker == 'kindle' or moniker == 'imdb_sents'):\n",
    "        ds.train['ct_label'] = ds.train['label'].apply(lambda x: 0-x)\n",
    "        ds.test['ct_label'] = ds.test['label'].apply(lambda x: 0-x)\n",
    "\n",
    "    display(ds.test.head(2))\n",
    "\n",
    "\n",
    "#     if(moniker == 'kindle'):\n",
    "#         pickle.dump(ds, open(data_path+\"kindle_ct/causal_sents/ds_kindle.pkl\", \"wb\"))\n",
    "#     elif(moniker == 'imdb'):\n",
    "#         pickle.dump(ds, open(data_path+\"imdb_ct/sentiment/combined/paired/paragraph/ds_imdb.pkl\", \"wb\"))\n",
    "#     elif(moniker == 'imdb_sents'):\n",
    "#         pickle.dump(ds, open(data_path+\"imdb_ct/sentiment/combined/paired/split_sents/ds_imdb.pkl\", \"wb\"))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for imdb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ct_text_amt</th>\n",
       "      <th>label</th>\n",
       "      <th>ct_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Long, boring, blasphemous. Never have I been so glad to see ending credits roll.</td>\n",
       "      <td>Long, fascinating, soulful. Never have I been so sad to see ending credits roll.</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id  \\\n",
       "0  4          \n",
       "\n",
       "                                                                               text  \\\n",
       "0  Long, boring, blasphemous. Never have I been so glad to see ending credits roll.   \n",
       "\n",
       "                                                                        ct_text_amt  \\\n",
       "0  Long, fascinating, soulful. Never have I been so sad to see ending credits roll.   \n",
       "\n",
       "   label  ct_label  \n",
       "0 -1      1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: dict_items([(-1, 851), (1, 856)])\n",
      "Test: dict_items([(-1, 243), (1, 245)])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.81      0.81       243\n",
      "           1       0.81      0.82      0.81       245\n",
      "\n",
      "    accuracy                           0.81       488\n",
      "   macro avg       0.81      0.81      0.81       488\n",
      "weighted avg       0.81      0.81      0.81       488\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.81      0.81       243\n",
      "           1       0.81      0.82      0.81       245\n",
      "\n",
      "    accuracy                           0.81       488\n",
      "   macro avg       0.81      0.81      0.81       488\n",
      "weighted avg       0.81      0.81      0.81       488\n",
      "\n",
      "Features correlated with pos class: \n",
      " ['romantic/1.348', 'great/1.288', 'perfect/1.092', 'wonderful/1.029', 'gives/0.977', 'classic/0.92', 'enjoyed/0.839', 'especially/0.8', 'surprised/0.798', 'fun/0.773', 'love/0.767', 'romance/0.764', 'works/0.716', 'both/0.689', 'special/0.688', 'bit/0.675', 'liked/0.666', 'fans/0.662', 'perfectly/0.66', 'knew/0.653', 'girls/0.642', 'excellent/0.64', 'superb/0.64', 'highly/0.636', 'feelings/0.633', 'historical/0.629', 'wonderfully/0.626', 'performances/0.61', 'own/0.603', 'believable/0.602', 'gets/0.6', 'era/0.593', 'movies/0.591', 'present/0.591', 'amazing/0.589', 'english/0.588', 'times/0.585', 'lives/0.584', 'awesome/0.584', 'loved/0.582', 'realistic/0.581', 'future/0.564', 'will/0.552', 'america/0.552', 'everyone/0.551', 'together/0.549', 'enjoy/0.549', 'recommended/0.546', 'able/0.54', 'moving/0.532', 'tears/0.53', 'leave/0.527', 'cast/0.526', 'my/0.524', 'spirit/0.523', 'portrayal/0.514', 'best/0.514', 'subtitles/0.513', 'appropriate/0.513', 'thriller/0.511', 'hot/0.501', 'easy/0.498', 'ending/0.498', 'visuals/0.498', 'beauty/0.497', 'beautiful/0.495', 'charming/0.493', 'number/0.491', 'simple/0.491', 'honest/0.486', 'know/0.484', 'today/0.481', 'recommend/0.475', 'intelligent/0.473', 'also/0.472', 'dreams/0.466', 'supporting/0.463', 'grand/0.461', 'refreshing/0.46', 'brought/0.459', 'favorite/0.459', 'ahead/0.457', 'sweet/0.452', 'heart/0.449', 'trip/0.44', 'sure/0.44', 'dramatic/0.437', 'viewing/0.437', 'aren/0.436', 'well/0.436', 'obviously/0.434', 'very/0.433', 'helped/0.427', 'compelling/0.425', 'beautifully/0.423', 'entertaining/0.422', 'our/0.422', 'incredible/0.419', 'action/0.419', 'rock/0.417', 'accurate/0.417', 'years/0.416', 'rare/0.414', 'comedy/0.412', 'return/0.411', 'fantastic/0.411', 'genius/0.407', 'than/0.401', 'whoopi/0.401', 'politics/0.4']\n",
      "\n",
      "Features correlated with neg class: \n",
      " ['horror/-1.7', 'worst/-1.562', 'terrible/-1.283', 'bad/-1.24', 'boring/-1.142', 'awful/-1.137', 'worse/-0.984', 'poor/-0.868', 'unfortunately/-0.857', 'effort/-0.819', 'dull/-0.81', 'stupid/-0.806', 'starts/-0.803', 'waste/-0.786', 'okay/-0.772', 'cannot/-0.748', 'something/-0.735', 'money/-0.728', 'known/-0.72', 'poorly/-0.719', 'pointless/-0.709', 'sorry/-0.691', 'predictable/-0.68', 'horrible/-0.67', 'skip/-0.66', 'nothing/-0.655', 'bunch/-0.646', 'talent/-0.643', 'seems/-0.63', 'during/-0.625', 'like/-0.616', 'your/-0.614', 'struggling/-0.608', 'silly/-0.597', 'actors/-0.592', 'script/-0.592', 'disappointing/-0.588', 'wanted/-0.585', '20/-0.585', 'pathetic/-0.583', 'unless/-0.579', 'whole/-0.577', 'cause/-0.569', 'lacks/-0.541', 'all/-0.534', 'instead/-0.534', 'god/-0.532', 'probably/-0.531', 'killed/-0.52', 'reason/-0.519', 'supposed/-0.517', 'rather/-0.495', 'tries/-0.494', 'getting/-0.494', 'theater/-0.493', 'take/-0.49', 'wrong/-0.489', '30/-0.488', 'cut/-0.488', 'woman/-0.487', 'killing/-0.487', 'direction/-0.485', 'highlight/-0.483', 'barely/-0.482', 'wife/-0.481', 'cable/-0.481', 'given/-0.479', 'minutes/-0.477', 'oh/-0.475', 'lines/-0.475', 'standing/-0.474', 'cheap/-0.474', 'badly/-0.473', 'dreadful/-0.473', 'christian/-0.472', 'guess/-0.471', 'could/-0.47', 'generation/-0.469', 'anything/-0.467', 'course/-0.463', 'set/-0.463', 'church/-0.456', 'left/-0.455', 'act/-0.453', 'producers/-0.449', 'interesting/-0.448', 'line/-0.448', 'sucked/-0.446', 'joke/-0.446', 'save/-0.442', 'annoying/-0.44', 'versus/-0.438', 'wow/-0.438', 'trite/-0.436', 'attempting/-0.436', 'zombies/-0.435', 'avoid/-0.435', 'failed/-0.431', 'don/-0.431', 'wasted/-0.431', 'rental/-0.43', 'thousand/-0.43', 'am/-0.426', 'lady/-0.426', 'high/-0.423', 'opinion/-0.423', 'bland/-0.422', 'gun/-0.416', 'across/-0.416', 'wanting/-0.414', 'bbc/-0.413', 'sadly/-0.413', 'lame/-0.409', 'cover/-0.408', 'let/-0.408', 'someone/-0.406', '60s/-0.405', 'hated/-0.405', 'revenge/-0.404', 'turned/-0.403', 'personally/-0.401']\n",
      "\n",
      "231 top terms: 110 pos, 121 neg, 0 missing from full vocab\n",
      "\n",
      "Missing terms: []\n",
      "\n",
      "Get antonyms for 65 out of 65 causal terms\n",
      "Closest opposite match identified causal terms: 27 out of 32\n",
      "\n",
      "1618 out of 1707 sentences include 65 causal words\n",
      "455 out of 488 sentences include 65 causal words\n",
      "1703 out of 1707 sentences include 166 bad words\n",
      "484 out of 488 sentences include 166 bad words\n",
      "1705 out of 1707 sentences include 231 top words\n",
      "488 out of 488 sentences include 231 top words\n",
      "1285 out of 1707 sentences include 32 identified_causal words\n",
      "360 out of 488 sentences include 32 identified_causal words\n",
      "1694 out of 1707 sentences include 282 all_causal words\n",
      "483 out of 488 sentences include 282 all_causal words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ct_text_amt</th>\n",
       "      <th>label</th>\n",
       "      <th>ct_label</th>\n",
       "      <th>causal_wds</th>\n",
       "      <th>n_causal_wds</th>\n",
       "      <th>ct_text_causal</th>\n",
       "      <th>ct_causal_wds</th>\n",
       "      <th>bad_wds</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_text_top</th>\n",
       "      <th>ct_top_wds</th>\n",
       "      <th>identified_causal_wds</th>\n",
       "      <th>n_identified_causal_wds</th>\n",
       "      <th>ct_text_identified_causal</th>\n",
       "      <th>ct_identified_causal_wds</th>\n",
       "      <th>all_causal_wds</th>\n",
       "      <th>n_all_causal_wds</th>\n",
       "      <th>ct_text_all_causal</th>\n",
       "      <th>ct_all_causal_wds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>If you haven't seen this, it's terrible. It is pure trash. I saw this about 17 years ago, and I'm still screwed up from it.</td>\n",
       "      <td>If you haven't seen this, it's incredible. It is pure gold. I saw this about 17 years ago, and I'm still hype about it.</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[terrible]</td>\n",
       "      <td>1</td>\n",
       "      <td>if you haven t seen this it s nice it is pure trash i saw this about 17 years ago and i m still screwed up from it</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>[years]</td>\n",
       "      <td>...</td>\n",
       "      <td>if you haven t seen this it s nice it is pure trash i saw this about 17 young ago and i m still screwed up from it</td>\n",
       "      <td>[nice, young]</td>\n",
       "      <td>[terrible]</td>\n",
       "      <td>1</td>\n",
       "      <td>if you haven t seen this it s nice it is pure trash i saw this about 17 years ago and i m still screwed up from it</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>[terrible, trash]</td>\n",
       "      <td>2</td>\n",
       "      <td>if you haven t seen this it s nice it is pure heat i saw this about 17 years ago and i m still screwed up from it</td>\n",
       "      <td>[nice, heat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>being a NI supporter, it's hard to objectively review a movie glorifying ulster nationalists. characters who are hard to root for, typical heavy-handed anti-violence messages, and a predictable 'poetic justice' ending makes this an awkward watch...</td>\n",
       "      <td>being a NI supporter, it's easy to objectively review a movie glorifying ulster nationalists. characters who are painless to root for, typical heavy-handed anti-violence messages, and a unpredictable 'poetic justice' ending makes this an unforgettable watch...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[predictable]</td>\n",
       "      <td>1</td>\n",
       "      <td>being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch</td>\n",
       "      <td>[unpredictable]</td>\n",
       "      <td>[ending]</td>\n",
       "      <td>...</td>\n",
       "      <td>being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice block makes this an awkward watch</td>\n",
       "      <td>[unpredictable, block]</td>\n",
       "      <td>[predictable]</td>\n",
       "      <td>1</td>\n",
       "      <td>being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch</td>\n",
       "      <td>[unpredictable]</td>\n",
       "      <td>[predictable]</td>\n",
       "      <td>1</td>\n",
       "      <td>being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch</td>\n",
       "      <td>[unpredictable]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id  \\\n",
       "0  13         \n",
       "1  46         \n",
       "\n",
       "                                                                                                                                                                                                                                                       text  \\\n",
       "0  If you haven't seen this, it's terrible. It is pure trash. I saw this about 17 years ago, and I'm still screwed up from it.                                                                                                                                \n",
       "1  being a NI supporter, it's hard to objectively review a movie glorifying ulster nationalists. characters who are hard to root for, typical heavy-handed anti-violence messages, and a predictable 'poetic justice' ending makes this an awkward watch...   \n",
       "\n",
       "                                                                                                                                                                                                                                                            ct_text_amt  \\\n",
       "0  If you haven't seen this, it's incredible. It is pure gold. I saw this about 17 years ago, and I'm still hype about it.                                                                                                                                                \n",
       "1  being a NI supporter, it's easy to objectively review a movie glorifying ulster nationalists. characters who are painless to root for, typical heavy-handed anti-violence messages, and a unpredictable 'poetic justice' ending makes this an unforgettable watch...   \n",
       "\n",
       "   label  ct_label     causal_wds  n_causal_wds  \\\n",
       "0 -1      1         [terrible]     1              \n",
       "1 -1      1         [predictable]  1              \n",
       "\n",
       "                                                                                                                                                                                                                                      ct_text_causal  \\\n",
       "0  if you haven t seen this it s nice it is pure trash i saw this about 17 years ago and i m still screwed up from it                                                                                                                                  \n",
       "1  being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch   \n",
       "\n",
       "     ct_causal_wds   bad_wds  ...  \\\n",
       "0  [nice]           [years]   ...   \n",
       "1  [unpredictable]  [ending]  ...   \n",
       "\n",
       "                                                                                                                                                                                                                                        ct_text_top  \\\n",
       "0  if you haven t seen this it s nice it is pure trash i saw this about 17 young ago and i m still screwed up from it                                                                                                                                 \n",
       "1  being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice block makes this an awkward watch   \n",
       "\n",
       "               ct_top_wds identified_causal_wds n_identified_causal_wds  \\\n",
       "0  [nice, young]           [terrible]            1                        \n",
       "1  [unpredictable, block]  [predictable]         1                        \n",
       "\n",
       "                                                                                                                                                                                                                           ct_text_identified_causal  \\\n",
       "0  if you haven t seen this it s nice it is pure trash i saw this about 17 years ago and i m still screwed up from it                                                                                                                                  \n",
       "1  being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch   \n",
       "\n",
       "  ct_identified_causal_wds     all_causal_wds n_all_causal_wds  \\\n",
       "0  [nice]                   [terrible, trash]  2                 \n",
       "1  [unpredictable]          [predictable]      1                 \n",
       "\n",
       "                                                                                                                                                                                                                                  ct_text_all_causal  \\\n",
       "0  if you haven t seen this it s nice it is pure heat i saw this about 17 years ago and i m still screwed up from it                                                                                                                                   \n",
       "1  being a ni supporter it s hard to objectively review a movie glorifying ulster nationalists characters who are hard to root for typical heavy handed anti violence messages and a unpredictable poetic justice ending makes this an awkward watch   \n",
       "\n",
       "  ct_all_causal_wds  \n",
       "0  [nice, heat]      \n",
       "1  [unpredictable]   \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_imdb = run_experiment(moniker='imdb_L',coef_thresh=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for imdb_sents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Long, boring, blasphemous.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id                        text  label\n",
       "0  4         Long, boring, blasphemous. -1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: dict_items([(-1, 4059), (1, 4114)])\n",
      "Test: dict_items([(-1, 1101), (1, 1144)])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.70      0.70      1101\n",
      "           1       0.71      0.72      0.72      1144\n",
      "\n",
      "    accuracy                           0.71      2245\n",
      "   macro avg       0.71      0.71      0.71      2245\n",
      "weighted avg       0.71      0.71      0.71      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.70      0.70      1101\n",
      "           1       0.71      0.72      0.72      1144\n",
      "\n",
      "    accuracy                           0.71      2245\n",
      "   macro avg       0.71      0.71      0.71      2245\n",
      "weighted avg       0.71      0.71      0.71      2245\n",
      "\n",
      "Features correlated with pos class: \n",
      " ['romantic/2.919', 'perfect/2.151', 'wonderful/1.927', 'sweet/1.732', 'magnificent/1.695', 'beautifully/1.694', 'journey/1.653', 'romance/1.646', 'subtle/1.613', 'appropriate/1.598', 'feature/1.535', 'excellent/1.512', 'enjoyed/1.464', 'especially/1.436', 'verhoeven/1.429', 'chan/1.406', 'drama/1.386', 'superior/1.383', 'surprised/1.369', 'terrific/1.368', 'superb/1.366', 'prince/1.365', 'refreshing/1.364', 'miss/1.36', 'superbly/1.359', 'grand/1.344', 'fabulous/1.34', 'outstanding/1.331', 'rough/1.314', 'awesome/1.308', 'delightful/1.306', 'core/1.303', 'kim/1.301', 'countries/1.3', 'fun/1.299', 'intelligent/1.283', 'greatest/1.281', 'forget/1.267', 'need/1.259', 'awe/1.251', 'together/1.241', 'funniest/1.234', 'shock/1.232', 'chess/1.227', 'powerful/1.226', 'simon/1.216', 'favorite/1.211', 'beauty/1.209', 'delight/1.208', 'great/1.208', 'creative/1.2', 'amazing/1.193', 'portrait/1.177', 'impact/1.173', 'guessing/1.169', 'classic/1.162', 'adorable/1.161', 'perfectly/1.152', 'tend/1.142', 'meets/1.127', 'full/1.126', 'entertains/1.122', 'english/1.122', 'perfection/1.115', 'bourne/1.107', 'works/1.105', 'began/1.102', 'puts/1.101', 'simple/1.092', 'quick/1.091', 'super/1.09', 'moving/1.088', 'fantastic/1.083', 'rare/1.083', 'enjoy/1.081', 'arthur/1.077', 'city/1.072', 'holds/1.062', 'gorgeous/1.054', 'stops/1.053', 'sees/1.046', 'spoiled/1.046', 'thrown/1.042', 'anger/1.041', 'feelings/1.038', 'crash/1.036', 'finish/1.036', 'surprisingly/1.031', 'addition/1.031', 'glover/1.027', 'own/1.025', 'loved/1.023', 'unique/1.023', 'extraordinary/1.019', 'exciting/1.019', 'ward/1.017', 'born/1.016', 'husbands/1.014', 'believable/1.012', 'sutherland/1.0']\n",
      "\n",
      "Features correlated with neg class: \n",
      " ['worst/-2.185', 'waste/-2.171', 'awful/-2.155', 'talent/-2.069', 'pointless/-2.044', 'horror/-2.039', 'terrible/-1.963', 'poorly/-1.882', 'lacks/-1.855', 'worse/-1.658', 'stupid/-1.658', 'sucks/-1.614', 'poor/-1.558', 'wasting/-1.54', 'dreadful/-1.519', 'boring/-1.518', 'sellers/-1.507', 'dull/-1.497', 'badly/-1.477', 'videos/-1.475', 'bad/-1.464', 'wasted/-1.442', 'fails/-1.428', 'effort/-1.367', 'bland/-1.354', 'jesus/-1.345', 'idiotic/-1.343', 'uninspired/-1.336', 'joke/-1.336', 'fail/-1.323', 'cover/-1.322', 'thinks/-1.301', 'okay/-1.296', 'disappointing/-1.294', 'sandler/-1.29', 'unfortunately/-1.29', 'prophecy/-1.284', 'christian/-1.262', 'surely/-1.257', 'filming/-1.255', 'unfunny/-1.233', 'pile/-1.227', 'chose/-1.218', 'attack/-1.216', 'nonsensical/-1.214', 'theater/-1.214', 'bridge/-1.18', 'scary/-1.179', 'ii/-1.177', 'painful/-1.175', 'westerns/-1.172', 'asks/-1.165', 'con/-1.156', 'camera/-1.153', 'cannot/-1.151', 'kinda/-1.14', 'hated/-1.138', 'tries/-1.136', 'predictable/-1.134', 'skin/-1.124', 'team/-1.122', 'cable/-1.121', 'convince/-1.115', 'generate/-1.112', 'atrocious/-1.111', 'naschy/-1.111', 'annoying/-1.11', 'stand/-1.107', 'protagonist/-1.104', 'seems/-1.103', 'offensive/-1.098', 'author/-1.097', 'mediocre/-1.093', 'car/-1.088', 'bizarre/-1.086', 'cheap/-1.078', 'bright/-1.076', 'andy/-1.076', 'clark/-1.067', 'elvis/-1.058', 'failed/-1.054', 'something/-1.054', 'lacking/-1.053', 'oh/-1.052', 'trite/-1.044', 'extremely/-1.041', 'cruel/-1.04', 'revenge/-1.027', 'helps/-1.027', 'produced/-1.025', 'shoot/-1.019', 'neither/-1.018', 'hackman/-1.016', 'cold/-1.014', 'doo/-1.014', 'suicide/-1.012', 'instead/-1.011', 'bought/-1.004']\n",
      "\n",
      "198 top terms: 100 pos, 98 neg, 15 missing from full vocab\n",
      "\n",
      "Missing terms: ['began', 'born', 'bought', 'chose', 'convince', 'doo', 'generate', 'glover', 'sees', 'simon', 'suicide', 'super', 'surprisingly', 'sutherland', 'ward']\n",
      "\n",
      "Get antonyms for 80 out of 80 causal terms\n",
      "Closest opposite match identified causal terms: 27 out of 32\n",
      "\n",
      "3655 out of 8173 sentences include 80 causal words\n",
      "987 out of 2245 sentences include 80 causal words\n",
      "1842 out of 8173 sentences include 118 bad words\n",
      "458 out of 2245 sentences include 118 bad words\n",
      "4714 out of 8173 sentences include 198 top words\n",
      "1231 out of 2245 sentences include 198 top words\n",
      "2577 out of 8173 sentences include 32 identified_causal words\n",
      "739 out of 2245 sentences include 32 identified_causal words\n",
      "8063 out of 8173 sentences include 285 all_causal words\n",
      "2229 out of 2245 sentences include 285 all_causal words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>causal_wds</th>\n",
       "      <th>n_causal_wds</th>\n",
       "      <th>ct_text_causal</th>\n",
       "      <th>ct_causal_wds</th>\n",
       "      <th>bad_wds</th>\n",
       "      <th>n_bad_wds</th>\n",
       "      <th>ct_text_bad</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_top_wds</th>\n",
       "      <th>identified_causal_wds</th>\n",
       "      <th>n_identified_causal_wds</th>\n",
       "      <th>ct_text_identified_causal</th>\n",
       "      <th>ct_identified_causal_wds</th>\n",
       "      <th>all_causal_wds</th>\n",
       "      <th>n_all_causal_wds</th>\n",
       "      <th>ct_text_all_causal</th>\n",
       "      <th>ct_all_causal_wds</th>\n",
       "      <th>ct_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>If you haven't seen this, it's terrible.</td>\n",
       "      <td>-1</td>\n",
       "      <td>[terrible]</td>\n",
       "      <td>1</td>\n",
       "      <td>if you haven t seen this it s nice</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>[terrible]</td>\n",
       "      <td>1</td>\n",
       "      <td>if you haven t seen this it s nice</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>[terrible]</td>\n",
       "      <td>1</td>\n",
       "      <td>if you haven t seen this it s nice</td>\n",
       "      <td>[nice]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>It is pure trash.</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[trash]</td>\n",
       "      <td>1</td>\n",
       "      <td>it is pure heat</td>\n",
       "      <td>[heat]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id                                      text  label  causal_wds  \\\n",
       "0  13        If you haven't seen this, it's terrible. -1      [terrible]   \n",
       "1  13        It is pure trash.                        -1      []           \n",
       "\n",
       "   n_causal_wds                      ct_text_causal ct_causal_wds bad_wds  \\\n",
       "0  1             if you haven t seen this it s nice  [nice]        []       \n",
       "1  0                                                 []            []       \n",
       "\n",
       "   n_bad_wds ct_text_bad  ... ct_top_wds identified_causal_wds  \\\n",
       "0  0                      ...  [nice]     [terrible]             \n",
       "1  0                      ...  []         []                     \n",
       "\n",
       "   n_identified_causal_wds           ct_text_identified_causal  \\\n",
       "0  1                        if you haven t seen this it s nice   \n",
       "1  0                                                             \n",
       "\n",
       "  ct_identified_causal_wds all_causal_wds  n_all_causal_wds  \\\n",
       "0  [nice]                   [terrible]     1                  \n",
       "1  []                       [trash]        1                  \n",
       "\n",
       "                   ct_text_all_causal ct_all_causal_wds ct_label  \n",
       "0  if you haven t seen this it s nice  [nice]            1        \n",
       "1  it is pure heat                     [heat]            1        \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_imdb_sents = run_experiment(moniker='imdb_S',coef_thresh=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for kindle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The story was good, but I was getting very irritated at all the grammatical and spelling errors</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>selected_train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              text  \\\n",
       "3  The story was good, but I was getting very irritated at all the grammatical and spelling errors   \n",
       "\n",
       "   rating  label            flag  \n",
       "3  2      -1      selected_train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: dict_items([(-1, 5000), (1, 5000)])\n",
      "Test: dict_items([(1, 250), (-1, 250)])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.92      0.89       250\n",
      "           1       0.91      0.86      0.88       250\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.89      0.89      0.89       500\n",
      "weighted avg       0.89      0.89      0.89       500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.92      0.89       250\n",
      "           1       0.91      0.86      0.88       250\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.89      0.89      0.89       500\n",
      "weighted avg       0.89      0.89      0.89       500\n",
      "\n",
      "Features correlated with pos class: \n",
      " ['disappoint/2.68', 'amazing/2.337', 'loved/2.329', 'wonderful/2.235', 'excellent/2.138', 'wait/1.944', 'loves/1.863', 'enjoyed/1.838', 'great/1.834', 'awesome/1.778', 'drag/1.757', 'perfect/1.735', 'beautiful/1.688', 'love/1.663', 'fun/1.654', 'expect/1.616', 'favorite/1.608', 'fascinating/1.596', 'job/1.59', 'wrong/1.586', 'complaint/1.566', 'wonderfully/1.566', 'enjoyable/1.521', 'fantastic/1.484', 'fabulous/1.474', 'sister/1.46', 'regret/1.454', 'waited/1.447', 'refreshing/1.444', 'super/1.438', 'tips/1.421', 'crazy/1.38', 'night/1.36', 'hot/1.354', 'gluten/1.316', 'putting/1.313', 'knew/1.305', 'summer/1.288', 'available/1.27', 'turns/1.264', 'loving/1.257', 'theme/1.244', 'vampire/1.228', 'happen/1.225', 'appreciate/1.216', 'tho/1.213', 'keeps/1.206', 'sexy/1.175', 'twists/1.158', 'wow/1.152', 'adventure/1.15', 'truly/1.143', 'forward/1.139', 'chemistry/1.137', 'delight/1.13', 'turning/1.125', 'likable/1.123', 'satisfying/1.12', 'appreciated/1.118', 'lucas/1.114', 'strong/1.11', 'down/1.101', 'growth/1.1', 'installment/1.094', 'entertain/1.094', 'different/1.07', 'series/1.069', 'brought/1.065', 'laura/1.064', 'couples/1.056', 'helps/1.046', 'clean/1.046', 'heartwarming/1.042', 'day/1.042', 'held/1.04', 'joy/1.029', 'immediately/1.028', 'fight/1.026', 'collection/1.025', 'exciting/1.023', '100/1.017', 'add/1.013', 'entertaining/1.01', 'blake/1.01', 'works/1.009', 'turner/1.004', 'picked/1.002']\n",
      "\n",
      "Features correlated with neg class: \n",
      " ['waste/-3.074', 'disappointing/-2.394', 'boring/-2.295', 'worst/-2.272', 'chapters/-2.216', 'poorly/-2.114', 'silly/-2.02', 'lame/-2.004', 'weird/-2.0', 'weak/-1.991', 'premise/-1.969', 'potential/-1.886', 'bored/-1.86', 'stupid/-1.853', 'sorry/-1.836', 'sounded/-1.774', 'unfortunately/-1.694', 'leaves/-1.658', 'nothing/-1.565', 'title/-1.542', '99/-1.539', 'poor/-1.516', 'shallow/-1.508', 'not/-1.502', 'idea/-1.501', 'awful/-1.46', 'met/-1.45', 'unless/-1.44', 'terrible/-1.432', 'reviews/-1.423', 'didn/-1.418', 'okay/-1.416', 'seemed/-1.414', 'free/-1.41', 'hopes/-1.407', 'dumb/-1.405', 'didnt/-1.394', 'horrible/-1.389', 'thinking/-1.385', 'annoying/-1.353', 'unbelievable/-1.345', 'lacking/-1.325', 'maybe/-1.32', 'chapter/-1.303', 'incomplete/-1.3', 'religious/-1.298', 'substance/-1.296', 'extremely/-1.293', 'kinds/-1.286', 'wasted/-1.281', 'sick/-1.28', 'product/-1.279', 'tedious/-1.278', 'tired/-1.276', 'something/-1.253', 'guess/-1.247', 'ridiculous/-1.246', 'attraction/-1.219', 'blurb/-1.217', 'immature/-1.217', 'blood/-1.215', 'minutes/-1.214', 'luck/-1.204', 'confusing/-1.203', 'expected/-1.196', 'wasn/-1.191', 'basic/-1.186', 'print/-1.184', 'girl/-1.183', 'editing/-1.177', 'perhaps/-1.177', 'news/-1.175', 'blah/-1.172', 'interest/-1.141', 'kinda/-1.137', 'violence/-1.133', 'someone/-1.127', 'supposed/-1.112', 'falls/-1.108', 'rush/-1.106', 'paid/-1.105', 'torture/-1.105', 'difficult/-1.103', 'lost/-1.092', 'errors/-1.089', 'meet/-1.089', 'thoughts/-1.088', 'stupidity/-1.086', 'badly/-1.083', '15/-1.083', 'remember/-1.078', 'may/-1.076', 'almost/-1.068', 'saying/-1.062', 'effort/-1.049', 'disappointment/-1.047', 'useless/-1.047', 'disgusting/-1.023', 'unrealistic/-1.016', 'deliver/-1.016', 'doesn/-1.013', 'no/-1.009', 'missed/-1.005', 'don/-1.005', 'text/-1.004', 'lacked/-1.002', 'cost/-1.002']\n",
      "\n",
      "194 top terms: 87 pos, 107 neg, 0 missing from full vocab\n",
      "\n",
      "Missing terms: []\n",
      "\n",
      "Get antonyms for 75 out of 76 causal terms\n",
      "Closest opposite match identified causal terms: 19 out of 23\n",
      "\n",
      "5700 out of 10000 sentences include 76 causal words\n",
      "249 out of 500 sentences include 76 causal words\n",
      "5063 out of 10000 sentences include 118 bad words\n",
      "230 out of 500 sentences include 118 bad words\n",
      "8386 out of 10000 sentences include 194 top words\n",
      "394 out of 500 sentences include 194 top words\n",
      "6038 out of 10000 sentences include 23 identified_causal words\n",
      "275 out of 500 sentences include 23 identified_causal words\n",
      "9967 out of 10000 sentences include 264 all_causal words\n",
      "430 out of 500 sentences include 264 all_causal words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>flag</th>\n",
       "      <th>causal_wds</th>\n",
       "      <th>n_causal_wds</th>\n",
       "      <th>ct_text_causal</th>\n",
       "      <th>ct_causal_wds</th>\n",
       "      <th>bad_wds</th>\n",
       "      <th>n_bad_wds</th>\n",
       "      <th>...</th>\n",
       "      <th>identified_causal_wds</th>\n",
       "      <th>n_identified_causal_wds</th>\n",
       "      <th>ct_text_identified_causal</th>\n",
       "      <th>ct_identified_causal_wds</th>\n",
       "      <th>all_causal_wds</th>\n",
       "      <th>n_all_causal_wds</th>\n",
       "      <th>ct_text_all_causal</th>\n",
       "      <th>ct_all_causal_wds</th>\n",
       "      <th>ct_text_amt</th>\n",
       "      <th>ct_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was a very fun story</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[fun]</td>\n",
       "      <td>1</td>\n",
       "      <td>this was a very frivolity story</td>\n",
       "      <td>[frivolity]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[fun]</td>\n",
       "      <td>1</td>\n",
       "      <td>this was a very frivolity story</td>\n",
       "      <td>[frivolity]</td>\n",
       "      <td>[fun]</td>\n",
       "      <td>1</td>\n",
       "      <td>this was a very frivolity story</td>\n",
       "      <td>[frivolity]</td>\n",
       "      <td>This was a very sad story</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not fast moving but a very well managed pace</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[not]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[not]</td>\n",
       "      <td>1</td>\n",
       "      <td>commercial fast moving but a very well managed pace</td>\n",
       "      <td>[commercial]</td>\n",
       "      <td>[well]</td>\n",
       "      <td>1</td>\n",
       "      <td>not fast moving but a very ill managed pace</td>\n",
       "      <td>[ill]</td>\n",
       "      <td>Not fast moving but a very poorly managed pace</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  rating  label  flag  \\\n",
       "0  This was a very fun story                     5       1      test   \n",
       "1  Not fast moving but a very well managed pace  5       1      test   \n",
       "\n",
       "  causal_wds  n_causal_wds                   ct_text_causal ct_causal_wds  \\\n",
       "0  [fun]      1             this was a very frivolity story  [frivolity]    \n",
       "1  []         0                                              []             \n",
       "\n",
       "  bad_wds  n_bad_wds  ... identified_causal_wds n_identified_causal_wds  \\\n",
       "0  []      0          ...  [fun]                 1                        \n",
       "1  [not]   1          ...  [not]                 1                        \n",
       "\n",
       "                             ct_text_identified_causal  \\\n",
       "0  this was a very frivolity story                       \n",
       "1  commercial fast moving but a very well managed pace   \n",
       "\n",
       "   ct_identified_causal_wds all_causal_wds n_all_causal_wds  \\\n",
       "0  [frivolity]               [fun]          1                 \n",
       "1  [commercial]              [well]         1                 \n",
       "\n",
       "                            ct_text_all_causal  ct_all_causal_wds  \\\n",
       "0  this was a very frivolity story              [frivolity]         \n",
       "1  not fast moving but a very ill managed pace  [ill]               \n",
       "\n",
       "                                      ct_text_amt ct_label  \n",
       "0  This was a very sad story                      -1        \n",
       "1  Not fast moving but a very poorly managed pace -1        \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_kindle = run_experiment(moniker='kindle',coef_thresh=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tf_bert",
   "language": "python",
   "name": "tf_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
